{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8081b139",
   "metadata": {},
   "source": [
    "## Example notebook running SiRCle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287129b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "from scircm import SciRCM\n",
    "import pandas as pd\n",
    "\n",
    "# FORMAT must be csv :) \n",
    "data_dir = 'data/'\n",
    "prot_file = f'{data_dir}prot_DE_Stage IV_sircle.csv'\n",
    "rna_file = f'{data_dir}rna_DE_Stage IV_sircle.csv'\n",
    "meth_file = f'{data_dir}filtered_cpg_DE_Stage IV_sircle.csv'\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1a0b3bca",
   "metadata": {},
   "source": [
    "### Had to run this originally but couldn't upload the data since the file was too big\n",
    "```\n",
    "from scircm import filter_methylation_data_by_genes\n",
    "import numpy as np\n",
    "meth_df = pd.read_csv(meth_file)\n",
    "# Note: you need to pass it: \n",
    "# 1) the gene ID column, here it is 'ensembl_gene_id'\n",
    "# 2) the padj column: here it is 'padj_meth'\n",
    "# 3) the logFC or test statistic column: here it is 'CpG_Beta_diff'\n",
    "# Since we don't have a beta diff between normal and tumour let's make one (used M values)\n",
    "meth_df['CpG_Beta_diff'] = np.mean(meth_df[[c for c in meth_df.columns if 'Tumor' in c]].values) - np.mean(meth_df[[c for c in meth_df.columns if 'Normal' in c]].values)\n",
    "filtered_meth_df = filter_methylation_data_by_genes(meth_df, 'ensembl_gene_id', 'padj_meth', 'CpG_Beta_diff')\n",
    "# Re point the meth file to be the filtered one\n",
    "meth_file = f'{data_dir}filtered_cpg_DE_Stage IV_sircle.csv'\n",
    "filtered_meth_df.to_csv(meth_file, index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d3f33",
   "metadata": {},
   "source": [
    "## Have a look at each DF to show what is in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6af9602",
   "metadata": {
    "tags": []
   },
   "source": [
    "pd.read_csv(prot_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d30d407",
   "metadata": {
    "tags": []
   },
   "source": [
    "pd.read_csv(rna_file) # Note we can see that the ensembl gene ID column is named Unnamed: 0 this is \n",
    "# From DESeq2 having it as the row name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0e9619",
   "metadata": {
    "tags": []
   },
   "source": [
    "rna_df = pd.read_csv(rna_file)\n",
    "rna_df.rename(columns={'Unnamed: 0': 'ensembl_gene_id'}, inplace=True)\n",
    "rna_df.to_csv(f'{data_dir}rna_DE_Stage IV_sircle_renamed-cols.csv', index=False)\n",
    "rna_file = f'{data_dir}rna_DE_Stage IV_sircle_renamed-cols.csv'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15296506",
   "metadata": {
    "tags": []
   },
   "source": [
    "pd.read_csv(meth_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "462d6333",
   "metadata": {},
   "source": [
    "## Run SiRCle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa48c52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Note we assume your methylation CpGs map to a single gene, if they don't see the section below.\n",
    "# logFC_rna = column name in your RNA file that has your RNA logFC (same for the protein and CpG)\n",
    "# padj_rna = column name in your RNA file that has your padj value (same for protein and CpG)\n",
    "# NOTE: these need to be unique from one another since we merge the datasets, if they aren't, you need\n",
    "# to update your csv files.\n",
    "# Lastly: ensembl_gene_id this is the gene ID column, All must use the same identifier, and this must be\n",
    "# labelled the same in each file, if it isn't, update your column names before running.\n",
    "rcm = SciRCM(meth_file, rna_file, prot_file, \n",
    "             \"logFC_rna\", \"padj_rna\", \"CpG_Beta_diff\", \"padj_meth\", \"logFC_protein\", \"padj_protein\",\n",
    "             \"ensembl_gene_id\", sep=',',\n",
    "             rna_padj_cutoff=0.05, \n",
    "             prot_padj_cutoff=0.05, \n",
    "             meth_padj_cutoff=0.05,\n",
    "             rna_logfc_cutoff=1.0, \n",
    "             prot_logfc_cutoff=0.5, \n",
    "             meth_diff_cutoff=0.1, \n",
    "             output_dir='',\n",
    "             non_coding_genes=['None'],\n",
    "             output_filename='RCM_Output.csv',\n",
    "             bg_type = '(P&M)|(P&R)|(M&R)'\n",
    "         )\n",
    "rcm.run()\n",
    "df = rcm.get_df()\n",
    "# That DF now has your rcm clustering results, how easy was that :D\n",
    "df # The three columns you now have are: Regulation_Grouping_1, Regulation_Grouping_2, Regulation_Grouping_3"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3253c64a",
   "metadata": {},
   "source": [
    "## Plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582b6a4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "import itertools\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "g = sns.catplot(data=df, x='RG2_Changes_filtered', kind=\"count\", \n",
    "               height=4)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(f'Clustered Stage IV patients')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "334eb7d9",
   "metadata": {},
   "source": [
    "### Save DF to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375028e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "df.to_csv(f'{data_dir}RCM.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cda9332c",
   "metadata": {},
   "source": [
    "## Look at enriched TF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599cdd71",
   "metadata": {
    "tags": []
   },
   "source": [
    "from scimotf import SciMotf_Doro\n",
    "from scimotf import plot_cluster_tf\n",
    "\n",
    "rcm_file = f'{data_dir}RCM.csv'\n",
    "tf_file = f'{data_dir}dorothea_hs_ABCD.csv'\n",
    "mo = SciMotf_Doro(doro_file=tf_file, cluster_file=rcm_file, \n",
    "                  cluster_id='RG2_Changes_filtered',\n",
    "                  cluster_gene_id='external_gene_name', # got to match motif\n",
    "                  padj_protein='padj_protein', logfc_protein='logFC_protein', padj_rna='padj_rna',\n",
    "                  logfc_rna='logFC_rna', output_dir=data_dir)\n",
    "\n",
    "df = mo.run(['A'], rcm_clusters=[\"TMDE\", \"TMDS\", \"MDS\", \"MDE\", \"TPDE\", \"TPDS\"])\n",
    "df.to_csv(f'{data_dir}scimotif_DORO_A.csv')\n",
    "plot_cluster_tf(f'{data_dir}scimotif_DORO_A.csv', save_fig=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0685590a",
   "metadata": {},
   "source": [
    "## Train model and compare two groups\n",
    "\n",
    "### First setup the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782196a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in the files that we used for DE analysis and remove any redundent columns\n",
    "# the VAE excpets just the ID as the index, and then the values\n",
    "df = pd.read_csv(f'{data_dir}RCM.csv')\n",
    "\n",
    "# First filter out any NA values (we're not interested in non SiRCle genes)\n",
    "rcm_df = df[df['RG2_Changes_filtered'] != 'None']\n",
    "\n",
    "rna_sample_file = f'{data_dir}rna_sample_data_Stage IV_sircle.csv'\n",
    "prot_sample_file = f'{data_dir}prot_sample_data_Stage IV_sircle.csv'\n",
    "# Now we want to merge the clinical info with the cases from the sample df\n",
    "meth_sample_file = f'{data_dir}cpg_sample_data_Stage IV_sircle.csv'\n",
    "\n",
    "rna_samples = list(pd.read_csv(rna_sample_file)['FullLabel'].values)\n",
    "prot_samples = list(pd.read_csv(prot_sample_file)['FullLabel'].values)\n",
    "meth_samples = list(pd.read_csv(meth_sample_file)['FullLabel'].values)\n",
    "# Only use the filtered i.e. one CpG to one gene mapping for the cpg data\n",
    "\n",
    "# ensembl_gene_id that same shared gene ID\n",
    "cpg_data_df = rcm_df[['ensembl_gene_id'] + meth_samples]\n",
    "rna_data_df = rcm_df[['ensembl_gene_id'] + rna_samples]\n",
    "protein_data_df = rcm_df[['ensembl_gene_id'] + prot_samples]\n",
    "\n",
    "\n",
    "meta_cols = ['ensembl_gene_id', 'external_gene_name', 'entrezgene_id', 'hgnc_symbol', \"logFC_rna\", \"padj_rna\", \n",
    "             \"CpG_Beta_diff\", \"padj_meth\", \"logFC_protein\", \"padj_protein\", \"RG2_Changes_filtered\"]\n",
    "\n",
    "\n",
    "# Save to input dir\n",
    "save_input_data = True\n",
    "meta_rcm_df = rcm_df[meta_cols].copy()\n",
    "meta_rcm_df.set_index('ensembl_gene_id', inplace=True)\n",
    "# Save to the input data dir folder.\n",
    "if save_input_data:\n",
    "    protein_data_df.to_csv(f'{data_dir}CPTAC_protein.csv', index=False)\n",
    "    rna_data_df.to_csv(f'{data_dir}CPTAC_rna.csv', index=False)\n",
    "    cpg_data_df.to_csv(f'{data_dir}CPTAC_cpg.csv', index=False)\n",
    "    meta_rcm_df.to_csv(f'{data_dir}RCM.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d260f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example sample data frame\n",
    "pd.read_csv(rna_sample_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4b663562",
   "metadata": {},
   "source": [
    "### Next train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "708a7506",
   "metadata": {
    "tags": []
   },
   "source": [
    "#from scircm import RCMStats\n",
    "missing_method='mean'\n",
    "label = missing_method\n",
    "sv = RCMStats(rcm_file=f'{data_dir}RCM.csv', \n",
    "              patient_sample_file=f'{data_dir}clinical_CPTAC_TCGA.csv', # Clinical file for all patients in the study\n",
    "              meth_file=f'{data_dir}CPTAC_cpg.csv', \n",
    "              meth_sample_file=meth_sample_file, \n",
    "              rna_file=f'{data_dir}CPTAC_rna.csv', \n",
    "              rna_sample_file=rna_sample_file,\n",
    "              protein_file=f'{data_dir}CPTAC_protein.csv', \n",
    "              protein_sample_file=prot_sample_file,\n",
    "              output_folder=data_dir, \n",
    "              regulatory_label='RG2_Changes_filtered',\n",
    "              column_id='FullLabel',\n",
    "              condition_column='CondId',\n",
    "              patient_id_column='SafeCases', # This is the column that is in each of the sample DFs\n",
    "              run_name=label,\n",
    "              normalise='rows', \n",
    "              verbose=True,\n",
    "             missing_method=missing_method)\n",
    "\n",
    "# Check out the patient info\n",
    "# Get the patient info that has been compiled from the provided sample files\n",
    "patient_info = sv.patient_clinical_df\n",
    "# Select the cases with 5 samples \n",
    "matching_patient_info = patient_info[patient_info['Sample counts'] == 5]\n",
    "matching_cases = matching_patient_info['SafeCases'].values\n",
    "print(\"total number of patients: \", len(patient_info), \" vs number with matching data: \", len(matching_patient_info))\n",
    "matching_cases"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573107ee-9cea-4380-bce5-a545679bd1bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "###############################################################################\n",
    "#                                                                             #\n",
    "#    This program is free software: you can redistribute it and/or modify     #\n",
    "#    it under the terms of the GNU General Public License as published by     #\n",
    "#    the Free Software Foundation, either version 3 of the License, or        #\n",
    "#    (at your option) any later version.                                      #\n",
    "#                                                                             #\n",
    "#    This program is distributed in the hope that it will be useful,          #\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n",
    "#    GNU General Public License for more details.                             #\n",
    "#                                                                             #\n",
    "#    You should have received a copy of the GNU General Public License        #\n",
    "#    along with this program. If not, see <http://www.gnu.org/licenses/>.     #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "import random\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scivae import VAE\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sciutil import SciUtil\n",
    "import json\n",
    "\n",
    "\n",
    "class RCMStats:\n",
    "    \"\"\"\n",
    "    Enables running a VAE on the RCM data.\n",
    "\n",
    "    Takes in the output of rcm and then for each SiRCLe cluster, trains a VAE. It returns the dataset which can be\n",
    "    used as input to calculating statistics on the DS.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rcm_file: str,\n",
    "                 patient_sample_file : str,\n",
    "                 meth_file: str,\n",
    "                 meth_sample_file: str,\n",
    "                 rna_file: str,\n",
    "                 rna_sample_file: str,\n",
    "                 protein_file: str,\n",
    "                 protein_sample_file: str,\n",
    "                 output_folder: str,\n",
    "                 condition_column: str,\n",
    "                 column_id: str,\n",
    "                 patient_id_column: str,\n",
    "                 config_file: str = None,\n",
    "                 regulatory_label='Regulation_Grouping_2',\n",
    "                 run_name: str = None,\n",
    "                 clinical_label: str = None,\n",
    "                 normalise='rows', verbose=False, missing_method='mean',\n",
    "                 iid=False):\n",
    "        self.config_json = f'{config_file}'\n",
    "        self.clinical_label = clinical_label\n",
    "        self.feature_columns = ['RNA-LogFC',\n",
    "                                'Protein-LogFC',\n",
    "                                'CpG-LogFC',\n",
    "                                'RNA-Tumor',\n",
    "                                'RNA-Normal',\n",
    "                                'Protein-Tumor',\n",
    "                                'Protein-Normal']\n",
    "        # Read in the data\n",
    "        self.regulatory_label = regulatory_label\n",
    "        self.rcm = pd.read_csv(rcm_file, index_col=0)\n",
    "        self.meth_data = pd.read_csv(meth_file, index_col=0)\n",
    "        self.rna_data = pd.read_csv(rna_file, index_col=0)\n",
    "        self.protein_data = pd.read_csv(protein_file, index_col=0)\n",
    "        self.run_name = run_name\n",
    "        # Read in the sample dfs\n",
    "        self.patient_id_column = patient_id_column  # This needs to be the same in all cases!\n",
    "        self.patient_clinical_df = pd.read_csv(patient_sample_file)\n",
    "        self.meth_sample_df = pd.read_csv(meth_sample_file)\n",
    "        self.rna_sample_df = pd.read_csv(rna_sample_file)\n",
    "        self.protein_sample_df = pd.read_csv(protein_sample_file)\n",
    "        self.condition_column = condition_column or 'condition_id'\n",
    "        self.column_id = column_id or 'column_id'\n",
    "        self.missing_method = missing_method # either 'mean' or 'clinical'\n",
    "        # For each of these files, normalise the rows to be between 0 and 1.\n",
    "        self.output_folder = output_folder\n",
    "        self.encoded_df = {}  # The encoded patient data.\n",
    "        self.trained_vae = {}\n",
    "        self.vae_input_df = {}\n",
    "        self.train_df = {}\n",
    "        self.raw_input_df = {} # The raw input data (i.e. no normaliseation).\n",
    "        self.normalise = normalise\n",
    "        self.u = SciUtil(debug_on=verbose)  # Set this optionally for verbosity\n",
    "        self.u.warn_p([\"WARNING: you cannot have underscores in your case_id names. Please check this before using\"\n",
    "                       \"this tool.\"])\n",
    "        self.check_files()\n",
    "        self.iid = iid\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save relevant files.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        encoded_df = pd.DataFrame()\n",
    "        input_df = pd.DataFrame()\n",
    "        raw_df = pd.DataFrame()\n",
    "        for reg_label in self.encoded_df:\n",
    "            df = self.encoded_df[reg_label]\n",
    "            df[self.regulatory_label] = reg_label\n",
    "            encoded_df = pd.concat([encoded_df, df])\n",
    "            df = self.vae_input_df[reg_label]\n",
    "            df[self.regulatory_label] = reg_label\n",
    "            input_df = pd.concat([input_df, df])\n",
    "            df = self.raw_input_df[reg_label]\n",
    "            df[self.regulatory_label] = reg_label\n",
    "            raw_df = pd.concat([raw_df, df])\n",
    "        encoded_df.to_csv(f'{self.output_folder}encoded_df_{self.run_name}.csv')\n",
    "        input_df.to_csv(f'{self.output_folder}vae_input_df_{self.run_name}.csv')\n",
    "        raw_df.to_csv(f'{self.output_folder}raw_input_df_{self.run_name}.csv')\n",
    "\n",
    "        # Also save the patient info\n",
    "        self.patient_clinical_df.to_csv(f'{self.output_folder}patient_info_{self.run_name}.csv', index=False)\n",
    "\n",
    "    def load_saved_vaes(self):\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            weight_file_path = f'{self.output_folder}{reg_label}-{self.run_name}-VAE-weights.h5'\n",
    "            optimizer_file_path = f'{self.output_folder}{reg_label}-{self.run_name}-VAE-optimizer.json'\n",
    "            config_json = f'{self.output_folder}{reg_label}-{self.run_name}-VAE-config.json'\n",
    "            with open(config_json, \"r\") as fp:\n",
    "                config = json.load(fp)\n",
    "            vae_m = VAE(np.ones((20, len(self.feature_columns))), np.ones((20, len(self.feature_columns))),\n",
    "                        list(np.ones(20)), config, vae_label=reg_label)\n",
    "            # Then decode the data\n",
    "            vae_m.load(weight_file_path, optimizer_file_path, config_json)\n",
    "            self.trained_vae[reg_label] = vae_m\n",
    "\n",
    "    def load_saved_inputs(self, filename):\n",
    "        \"\"\"\n",
    "        Optionally load a saved version of the input/training data patient data. Expected to have \"id\" as the\n",
    "        first column, then the cases and values, and the regulatory label for that gene.\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        input_df = pd.read_csv(filename, index_col=0)\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            self.vae_input_df[reg_label] = input_df[input_df[self.regulatory_label] == reg_label]\n",
    "\n",
    "    def load_saved_raws(self, filename):\n",
    "        \"\"\"\n",
    "        Optionally load a saved version of the input/training data patient data. Expected to have \"id\" as the\n",
    "        first column, then the cases and values, and the regulatory label for that gene.\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        input_df = pd.read_csv(filename, index_col=0)\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            self.raw_input_df[reg_label] = input_df[input_df[self.regulatory_label] == reg_label]\n",
    "\n",
    "    def load_saved_encodings(self, filename):\n",
    "        \"\"\"\n",
    "        Optionally load a saved version of the encoded patient data. Expected to have \"id\" as the\n",
    "        first column, then the cases and values, and the regulatory label for that gene.\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        input_df = pd.read_csv(filename, index_col=0)\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            self.encoded_df[reg_label] = input_df[input_df[self.regulatory_label] == reg_label]\n",
    "\n",
    "    def check_files(self):\n",
    "        \"\"\"\n",
    "        We need to check the loaded files to make sure they are in the correct format.\n",
    "\n",
    "        Checks:\n",
    "            1. The index of each of the data files overlaps with the regulatory clusters.\n",
    "            2. Each sample file must have a) condition_column (default = 'condition_id') which has values 1 = tumour or\n",
    "            0 = Normal and b) a column ID field (default = 'column_id') that maps to the column of that dataset,\n",
    "            c) a case ID (that is a patient ID: default='case_id' that maps to a patient ID in the patient_clinical_df\n",
    "            which has clinical information about the patient. case_ids can't have underscores in them.\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # Check 1.\n",
    "        rcm_genes = set(self.rcm.index.values)\n",
    "        protein_genes = set(self.protein_data.index.values)\n",
    "        rna_genes = set(self.rna_data.index.values)\n",
    "        meth_genes = set(self.meth_data.index.values)\n",
    "        total_overlap = len(rcm_genes & rna_genes & protein_genes & meth_genes)\n",
    "        self.u.dp(['Overlap between SiRCLe gene clusters and protein, RNA, and CpG: ', total_overlap, '\\n',\n",
    "                   f'If you used SiRCLe, this should be the total number of genes in your SiRCLe dataset. '\n",
    "                   f'{len(rcm_genes)}', '\\n First 5 gene IDs in RCM: ', list(rcm_genes)[0:5],\n",
    "                   '\\n First 5 gene IDs in Protein: ', list(protein_genes)[0:5],\n",
    "                   '\\n First 5 gene IDs in RNA: ', list(rna_genes)[0:5],\n",
    "                   '\\n First 5 gene IDs in Methylation: ', list(meth_genes)[0:5],\n",
    "                   ])\n",
    "        if total_overlap == 0:\n",
    "            self.u.err_p(['You had no overlap between your gene identifiers! That is not good, nothing will work.'\n",
    "                          'Please make sure your gene IDs are matching and are in the first column of your CSV file.'\n",
    "                          '\\nAlso ensure you are using a CSV not a TSV.'])\n",
    "            return\n",
    "\n",
    "        # Part 2.\n",
    "        if not self.check_cols_exist():\n",
    "            return\n",
    "\n",
    "        # Part 3. Check for duplicates\n",
    "        if len(self.protein_data[self.protein_data.index.duplicated()]) > 0:\n",
    "            num_dups = len(self.protein_data[self.protein_data.index.duplicated()])\n",
    "            self.u.warn_p(['Protein dataset contained duplicates! Dropping duplicate IDs, note you should do this '\n",
    "                           'before running SiRCle. We have just dropped it and kept the first entry. You had: ',\n",
    "                           num_dups, 'duplicates.'])\n",
    "            self.protein_data = self.protein_data[~self.protein_data.index.duplicated(keep='first')]\n",
    "        if len(self.rna_data[self.rna_data.index.duplicated()]):\n",
    "            num_dups = len(self.rna_data[self.rna_data.index.duplicated()])\n",
    "            self.u.warn_p(['RNA dataset contained duplicates! Dropping duplicate IDs, note you should do this '\n",
    "                           'before running SiRCle. We have just dropped it and kept the first entry. You had: ',\n",
    "                           num_dups, 'duplicates.'])\n",
    "            self.rna_data = self.rna_data[~self.rna_data.index.duplicated(keep='first')]\n",
    "        if len(self.meth_data[self.meth_data.index.duplicated()]) > 0:\n",
    "            num_dups = len(self.meth_data[self.meth_data.index.duplicated()])\n",
    "            self.u.warn_p(['DNA Methylation dataset contained duplicates! Dropping duplicate IDs,'\n",
    "                           ' note you should do this before running SiRCle. We have just dropped it and '\n",
    "                           'kept the first entry You had: ',\n",
    "                           num_dups, 'duplicates.'])\n",
    "            self.meth_data = self.meth_data[~self.meth_data.index.duplicated(keep='first')]\n",
    "        self.build_sample_df()\n",
    "\n",
    "    def get_sample_column(self, sample_df, case_id, condition_id):\n",
    "        \"\"\"\n",
    "        Get the column identifier for a given case, sample df and condition ID.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_df\n",
    "        case_id\n",
    "        condition_id\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        case_sample_df = sample_df[sample_df[self.patient_id_column] == case_id]\n",
    "        if len(sample_df) > 0:\n",
    "            value = case_sample_df[case_sample_df[self.condition_column] == condition_id][self.column_id].values\n",
    "            if len(value) > 0:\n",
    "                # only ever take one\n",
    "                if len(value) > 1:\n",
    "                    self.u.warn_p(['Had multiple samples for: ', case_id, 'just took the first one.',\n",
    "                                   value])\n",
    "                return value[0]\n",
    "        return None\n",
    "\n",
    "    def build_sample_df(self):\n",
    "        \"\"\"\n",
    "        Builds a sample DF containing the columns that refer to the tumour and normal samples for the dataframes.\n",
    "        This will help build the comparisons later on and also will make it clear which patients have had missing\n",
    "        data added in.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # Part 3. building the patient dataframe and making sure we have good data there (i.e. matching patients).\n",
    "        protein_tumour = []\n",
    "        rna_tumour = []\n",
    "        meth_tumour = []\n",
    "        protein_normal = []\n",
    "        rna_normal = []\n",
    "        meth_normal = []\n",
    "        counts = []\n",
    "        for i, case_id in enumerate(self.patient_clinical_df[self.patient_id_column].values):\n",
    "            protein_normal.append(self.get_sample_column(self.protein_sample_df, case_id, 0))\n",
    "            protein_tumour.append(self.get_sample_column(self.protein_sample_df, case_id, 1))\n",
    "            rna_normal.append(self.get_sample_column(self.rna_sample_df, case_id, 0))\n",
    "            rna_tumour.append(self.get_sample_column(self.rna_sample_df, case_id, 1))\n",
    "            meth_normal.append(self.get_sample_column(self.meth_sample_df, case_id, 0))\n",
    "            meth_tumour.append(self.get_sample_column(self.meth_sample_df, case_id, 1))\n",
    "            # Add the number of non NAs we got\n",
    "            count_data = 1 if protein_normal[i] is not None else 0\n",
    "            count_data += 1 if protein_tumour[i] is not None else 0\n",
    "            count_data += 1 if rna_normal[i] is not None else 0\n",
    "            count_data += 1 if rna_tumour[i] is not None else 0\n",
    "            count_data += 1 if meth_normal[i] is not None else 0\n",
    "            count_data += 1 if meth_tumour[i] is not None else 0\n",
    "            counts.append(count_data)\n",
    "        df = self.patient_clinical_df.copy()\n",
    "        # Make a new sample df incorperating this info.\n",
    "        df['Protein Tumour'] = protein_tumour\n",
    "        df['Protein Normal'] = protein_normal\n",
    "        df['RNA Tumour'] = rna_tumour\n",
    "        df['RNA Normal'] = rna_normal\n",
    "        df['CpG Tumour'] = meth_tumour\n",
    "        df['CpG Normal'] = meth_normal\n",
    "        df['Sample counts'] = counts\n",
    "        self.patient_clinical_df = df  # update possibly this is a bad idea...\n",
    "        return df\n",
    "\n",
    "    def check_cols_exist(self):\n",
    "        \"\"\"\n",
    "        Check required columns exist in the sample data frames.\n",
    "        Required columns:\n",
    "        Each sample file must have a) condition_column (default = 'condition_id') which has values 1 = tumour or\n",
    "            0 = Normal and b) a column ID field (default = 'column_id') that maps to the column of that dataset,\n",
    "            c) a case ID (that is a patient ID: default='case_id' that maps to a patient ID in the patient_clinical_df\n",
    "            which has clinical information about the patient. case_ids can't have underscores in them.\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        cols = [self.condition_column, self.column_id, self.patient_id_column]\n",
    "        # Check 2.\n",
    "        for required_column in cols:\n",
    "            if required_column not in self.meth_sample_df.columns:\n",
    "                self.u.err_p([f'Your {required_column} was not in your methylation sample file?',\n",
    "                              'This is needed. Nothing will work. Make sure your sample file is a CSV file.\\n',\n",
    "                              'Columns in the file you passed: ', self.meth_sample_df.columns])\n",
    "                return False\n",
    "            if required_column not in self.rna_sample_df.columns:\n",
    "                self.u.err_p([f'Your {required_column} was not in your RNA sample file?',\n",
    "                              'This is needed. Nothing will work. Make sure your sample file is a CSV file.\\n',\n",
    "                              'Columns in the file you passed: ', self.rna_sample_df.columns])\n",
    "                return False\n",
    "\n",
    "            if required_column not in self.protein_sample_df.columns:\n",
    "                self.u.err_p([f'Your {required_column} was not in your Protein sample file?',\n",
    "                              'This is needed. Nothing will work. Make sure your sample file is a CSV file.\\n',\n",
    "                              'Columns in the file you passed: ', self.protein_sample_df.columns])\n",
    "                return False\n",
    "        # Lastly check that the column id actually has overlaps with their data and they haven't done something dumb.\n",
    "        protein_cols = set(self.protein_data.columns) & set(self.protein_sample_df[self.column_id].values)\n",
    "        rna_cols = set(self.rna_data.columns) & set(self.rna_sample_df[self.column_id].values)\n",
    "        methylation_cols = set(self.meth_data.columns) & set(self.meth_sample_df[self.column_id].values)\n",
    "        if len(protein_cols) == 0:\n",
    "            self.u.err_p([f'You made a mistake...  {self.column_id} does not actually map to your protein data file?',\n",
    "                          'columns in your protein data file:', self.protein_data.columns,\n",
    "                          '\\n vs columns in your protein sample file: ', self.protein_sample_df[self.column_id].values])\n",
    "            return False\n",
    "        if len(rna_cols) == 0:\n",
    "            self.u.err_p([f'You made a mistake...  {self.column_id} does not actually map to your RNA data file?',\n",
    "                          'columns in your protein data file:', self.rna_data.columns,\n",
    "                          '\\n vs columns in your protein sample file: ', self.rna_sample_df[self.column_id].values])\n",
    "            return False\n",
    "\n",
    "        if len(methylation_cols) == 0:\n",
    "            self.u.err_p([f'You made a mistake...  {self.column_id} does not actually map to your Methylation data file?',\n",
    "                          'columns in your protein data file:', self.meth_data.columns,\n",
    "                          '\\n vs columns in your protein sample file: ', self.meth_sample_df[self.column_id].values])\n",
    "            return False\n",
    "\n",
    "        # Final, check that there were overlapping patients in all and in the patient dataframe.\n",
    "        patients_overlap = set(self.patient_clinical_df[self.patient_id_column].values) & \\\n",
    "                           set(self.protein_sample_df[self.patient_id_column].values) & \\\n",
    "                           set(self.rna_sample_df[self.patient_id_column].values) & \\\n",
    "                           set(self.meth_sample_df[self.patient_id_column].values)\n",
    "        if len(patients_overlap) == 0:\n",
    "            self.u.err_p([f'Hmmm your patient ids: ', self.patient_id_column, 'did not map in one of your sample files',\n",
    "                          ' or the patient clinical info, please check them and then try again.'])\n",
    "            return False\n",
    "\n",
    "        # Sanitise the columns (replace '_' with .)\n",
    "        self.patient_clinical_df[self.patient_id_column] = [c.replace('_', '.') for c in self.patient_clinical_df[self.patient_id_column].values]\n",
    "        self.protein_sample_df[self.patient_id_column] = [c.replace('_', '.') for c in self.protein_sample_df[self.patient_id_column].values]\n",
    "        self.rna_sample_df[self.patient_id_column] = [c.replace('_', '.') for c in self.rna_sample_df[self.patient_id_column].values]\n",
    "        self.meth_sample_df[self.patient_id_column] = [c.replace('_', '.') for c in self.meth_sample_df[self.patient_id_column].values]\n",
    "\n",
    "        # Yay they did good.\n",
    "        return True\n",
    "\n",
    "    def run_vae_stats(self, cond_label: str, cond0: str, cond1: str, label='', selected_cases=None, test_type='mannwhitneyu'):\n",
    "        \"\"\"\n",
    "        Run stats comparing samples with condition 1 vs condition 0, the cond_label column. This is a column\n",
    "        that must be present in all the sample data frames (for example, \"gender\" or \"stage).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cond_label: the label of column in the patient sample df of\n",
    "            the condition that we want to do that stats on e.g. gender, or stage\n",
    "        cond0: the value that we want to be the control (e.g. stage 1)\n",
    "        cond1: the value we want to test deviates from the control (e.g. stage 4)\n",
    "        label: the label for this test\n",
    "        include_missing: whether you want to include patients that are missing 1 or more data values e.g. only containes\n",
    "            tumour for the protein data as opposed to both tumour and normal.\n",
    "            If this is ticked, the data is filled with the mean value for that condition.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        cond1_cases_all = self.patient_clinical_df[self.patient_clinical_df[cond_label] == cond1][self.patient_id_column].values\n",
    "        cond0_cases_all = self.patient_clinical_df[self.patient_clinical_df[cond_label] == cond0][self.patient_id_column].values\n",
    "\n",
    "        if selected_cases is not None:\n",
    "            cond1_cases_all = [c for c in cond1_cases_all if c in selected_cases]\n",
    "            cond0_cases_all = [c for c in cond0_cases_all if c in selected_cases]\n",
    "\n",
    "        # Note since not all of these values may have been included, keep only the cases that also were in the input df\n",
    "        all_stats = pd.DataFrame()\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            encoded_data = self.encoded_df[reg_label]  # Get the pre-encoded data for these patients...\n",
    "\n",
    "            # Get it for each of the columns to align to\n",
    "            cols_to_align = ['Protein-LogFC', 'RNA-LogFC', 'CpG-LogFC']\n",
    "            cond0_cases = list(set([col for col in encoded_data.columns if col in cond0_cases_all]))\n",
    "            cond1_cases = list(set([col for col in encoded_data.columns if col in cond1_cases_all]))\n",
    "\n",
    "            alignment_column_1_values = []\n",
    "            alignment_column_0_values = []\n",
    "            # Also we want to make sure the columns are aligned to something biologicallly meaningful, so we want\n",
    "            # to add in their \"input data\" so it can be aligned to this and we do this on the non-normalised data\n",
    "            raw_input_df = self.raw_input_df[reg_label]\n",
    "            for c in cols_to_align:\n",
    "                # Get the mean value for this condition\n",
    "                cols = [col for col in raw_input_df.columns if c in col and col.split('_')[0] in cond1_cases]\n",
    "                data = np.nanmean(raw_input_df[cols].values, axis=1)\n",
    "                alignment_column_1_values.append(data)\n",
    "                cols = [col for col in raw_input_df.columns if c in col and col.split('_')[0] in cond0_cases]\n",
    "                data = np.nanmean(raw_input_df[cols].values, axis=1)\n",
    "                alignment_column_0_values.append(data)\n",
    "\n",
    "            # cond_0_encodings = {case_id: [encoded_data[case_id].values] for case_id in cond0_cases}\n",
    "            # cond_1_encodings = {case_id: [encoded_data[case_id].values] for case_id in cond1_cases}\n",
    "            stats_df = self.make_stats_df(test_type=test_type, id_vals=encoded_data['id'].values,\n",
    "                                          cond_1_encodings=encoded_data[cond1_cases],\n",
    "                                          cond_0_encodings=encoded_data[cond0_cases],\n",
    "                                          column_to_align_to=cols_to_align,\n",
    "                                          alignment_column_1_values=alignment_column_1_values,\n",
    "                                          alignment_column_0_values=alignment_column_0_values, cond0=cond0, cond1=cond1)\n",
    "            stats_df[self.regulatory_label] = reg_label\n",
    "            # Save the averages from the cols to align to as well\n",
    "            for i, c in enumerate(cols_to_align):\n",
    "                stats_df[f'{c} mean ({cond1})'] = alignment_column_1_values[i]\n",
    "                stats_df[f'{c} mean ({cond0})'] = alignment_column_0_values[i]\n",
    "                stats_df[f'{c} mean ({cond1}-{cond0})'] = alignment_column_1_values[i] - alignment_column_0_values[i]\n",
    "\n",
    "            self.test_for_normality(stats_df[f'Integrated mean ({cond0})'], f'{reg_label} Integrated mean ({cond0})')\n",
    "            self.test_for_normality(stats_df[f'Integrated mean ({cond1})'], f'{reg_label} Integrated mean ({cond1})')\n",
    "            all_stats = pd.concat([all_stats, stats_df])\n",
    "        all_stats.to_csv(f'{self.output_folder}stats_{cond1}-{cond0}_{self.run_name + label}.csv')\n",
    "        return all_stats\n",
    "\n",
    "    def test_for_normality(self, values, label, test_type: str = \"shapiro\"):\n",
    "        \"\"\" Perform a test for normality.\"\"\"\n",
    "        k2, p = stats.normaltest(values)\n",
    "        if p < 0.05:  # null hypothesis: x comes from a normal distribution\n",
    "            print(f'{label}: NOT normally distributed')\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def make_stats_df(self, test_type, id_vals, cond_1_encodings, cond_0_encodings, column_to_align_to,\n",
    "                      alignment_column_1_values, alignment_column_0_values, cond0, cond1):\n",
    "        # Now we want to perform the differential test on the data between cond 1 - cond 0\n",
    "        # If we have multiple samples we need to do this for each one\n",
    "        if len(id_vals) > 0:\n",
    "            stat_vals = []\n",
    "            p_vals = []\n",
    "            base_means_cond_0 = []\n",
    "            base_means_cond_1 = []\n",
    "            num_cond_0 = 0\n",
    "            num_cond_1 = 0\n",
    "\n",
    "            # For each case in the encodings we want to collect the values\n",
    "            for i in range(0, len(id_vals)):\n",
    "                # ToDo: extend to anova or other statistical tests for more data types.\n",
    "                cases_0_vals = cond_0_encodings.values[i]\n",
    "                cases_1_vals = cond_1_encodings.values[i]\n",
    "                num_cond_0 = len(cases_0_vals)\n",
    "                num_cond_1 = len(cases_1_vals)\n",
    "                # potentially wrap a try catch if there are all even numbers\n",
    "                if test_type == 't-test':\n",
    "                    t_stat, p_val = stats.ttest_ind(cases_1_vals, cases_0_vals)\n",
    "                else:\n",
    "                    t_stat, p_val = stats.mannwhitneyu(cases_1_vals, cases_0_vals)\n",
    "                if p_val == 0 or p_val > 1:\n",
    "                    p_val = 1.0\n",
    "                stat_vals.append(t_stat)\n",
    "                p_vals.append(p_val)\n",
    "                base_mean_cond_1 = np.nanmean(cases_1_vals)\n",
    "                base_mean_cond_0 = np.nanmean(cases_0_vals)\n",
    "                base_means_cond_0.append(base_mean_cond_0)\n",
    "                base_means_cond_1.append(base_mean_cond_1)\n",
    "            # Now we have the p-values we can perform the correction\n",
    "            reg, corrected_p_vals, a, b = multipletests(p_vals, method='fdr_bh', alpha=0.05, returnsorted=False)\n",
    "            # Return something similar to what you'd get from DEseq2\n",
    "            stats_df = pd.DataFrame()\n",
    "            stats_df['id'] = id_vals\n",
    "            stats_df[f'{test_type} stat ({cond1}-{cond0})'] = stat_vals\n",
    "            stats_df[f'Integrated padj ({cond1}-{cond0})'] = corrected_p_vals\n",
    "            stats_df[f'Integrated pval ({cond1}-{cond0})'] = p_vals\n",
    "            # Check if we have a column to align to\n",
    "            base_means_cond_1 = np.array(base_means_cond_1)\n",
    "            base_means_cond_0 = np.array(base_means_cond_0)\n",
    "            if column_to_align_to is not None:\n",
    "                # Go through each one and stop if we get over 0.5 correlation\n",
    "                for col_i in range(0, len(alignment_column_0_values)):\n",
    "                    mean_col_0 = alignment_column_0_values[col_i]  # Across genes\n",
    "                    mean_col_1 = alignment_column_1_values[col_i]\n",
    "                    col_0_corr = np.corrcoef(mean_col_0, base_means_cond_0)[0, 1]\n",
    "                    col_1_corr = np.corrcoef(mean_col_1, base_means_cond_1)[0, 1]\n",
    "                    if abs(col_0_corr) > 0.5 or abs(col_1_corr) > 0.5:\n",
    "                        if abs(col_0_corr) > abs(col_1_corr):\n",
    "                            direction = -1 if col_0_corr < 0 else 1\n",
    "                        else:\n",
    "                            direction = -1 if col_1_corr < 0 else 1\n",
    "                        # Convert both\n",
    "                        base_means_cond_0 = direction * base_means_cond_0\n",
    "                        base_means_cond_1 = direction * base_means_cond_1\n",
    "                        break # If none of them meet it then we don't change anything\n",
    "            # Compute difference as the distance between the two\n",
    "            distances = []\n",
    "            for i, cond_0 in enumerate(base_means_cond_0):\n",
    "                if cond_0 < 0:\n",
    "                    distances.append(base_means_cond_1[i] + abs(cond_0))\n",
    "                else:\n",
    "                    distances.append(base_means_cond_1[i] - abs(cond_0))\n",
    "            stats_df[f'Integrated diff ({cond1}-{cond0})'] = distances\n",
    "            stats_df[f'Integrated mean ({cond0})'] = base_means_cond_0\n",
    "            stats_df[f'Integrated mean ({cond1})'] = base_means_cond_1\n",
    "            self.u.dp(['Summary\\n', f'Cond1: {num_cond_1} vs Cond0: {num_cond_0}\\n',\n",
    "                       stats_df.describe()])\n",
    "            # Also make a copy that also contains all the info from all the cases\n",
    "            # make this optional later on...\n",
    "            for c in cond_0_encodings:\n",
    "                stats_df[f'{cond0}_{c}'] = cond_0_encodings[c].values\n",
    "            for c in cond_1_encodings:\n",
    "                stats_df[f'{cond1}_{c}'] = cond_1_encodings[c].values\n",
    "            return stats_df\n",
    "        else:\n",
    "            # Only one value so just do the test once.\n",
    "            cases_0_vals = [c for c in cond_0_encodings.values]\n",
    "            cases_1_vals = [c for c in cond_1_encodings.values]\n",
    "            t_stat, p_val = stats.mannwhitneyu(cases_1_vals, cases_0_vals)\n",
    "            return t_stat, p_val\n",
    "\n",
    "    def merge_data(self, protein_data, rna_data, meth_data):\n",
    "        return pd.concat([protein_data, rna_data, meth_data], axis=1)\n",
    "\n",
    "    def train_vae(self, cases, config=None, include_missing=True):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cases: a list of patient identifiers which should be used for training, these are ideally, high quality with\n",
    "        no missing data.\n",
    "        config: a dictionary of configuration for the VAE training\n",
    "        include_missing: whether or not to include patients that are missing some data (it is filled in by the mean value)\n",
    "        note we only allow missing in terms of the \"normal\" not the tumour.\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        encoded_df = pd.DataFrame()\n",
    "        for reg_label in self.rcm[self.regulatory_label].unique():\n",
    "            if reg_label != \"None\":\n",
    "                rcm_df = self.rcm[self.rcm[self.regulatory_label] == reg_label].copy()\n",
    "                meth_data = self.compute_columns_training(self.align_to_rcm(self.meth_data, rcm_df), self.meth_sample_df, 'CpG',\n",
    "                                                          include_missing)\n",
    "                rna_data = self.compute_columns_training(self.align_to_rcm(self.rna_data,  rcm_df), self.rna_sample_df, 'RNA',\n",
    "                                                         include_missing)\n",
    "                protein_data = self.compute_columns_training(self.align_to_rcm(self.protein_data, rcm_df,\n",
    "                                                                               include_regulatory_label=True),\n",
    "                                                             self.protein_sample_df,\n",
    "                                                             'Protein', include_missing)\n",
    "\n",
    "                r_df = self.merge_data(protein_data, rna_data, meth_data)\n",
    "                self.vae_input_df[reg_label] = r_df.copy()  # Keep track of the training dataframe for these patients\n",
    "                # Also do the same for a non-normalised version, we want this so that we can actually get the change\n",
    "                # in protein etc.\n",
    "                nn_meth_data = self.compute_columns_training(self.align_to_rcm(self.meth_data, rcm_df, normalise=False),\n",
    "                                                          self.meth_sample_df, 'CpG',\n",
    "                                                          include_missing)\n",
    "                nn_rna_data = self.compute_columns_training(self.align_to_rcm(self.rna_data, rcm_df, normalise=False), self.rna_sample_df,\n",
    "                                                         'RNA',\n",
    "                                                         include_missing)\n",
    "                nn_protein_data = self.compute_columns_training(self.align_to_rcm(self.protein_data, rcm_df, normalise=False,\n",
    "                                                                               include_regulatory_label=True),\n",
    "                                                             self.protein_sample_df,\n",
    "                                                             'Protein', include_missing)\n",
    "                self.raw_input_df[reg_label] = self.merge_data(nn_protein_data, nn_rna_data, nn_meth_data)\n",
    "                # Now we need to filter out patients that didn't have the required matching data.\n",
    "                train_df = self.build_training_df(r_df, selected_cases=cases)\n",
    "                self.train_df[reg_label] = train_df.copy()\n",
    "                self.train(train_df, self.feature_columns, reg_label, config)\n",
    "                # Encode data with trained VAE for all patients.\n",
    "                # encoding has genes as the rows IDs and patients as the columns, so we're basically building it up\n",
    "                # for each of the patients\n",
    "                reg_encoded_df = self.get_encoding(r_df, reg_label)\n",
    "                reg_encoded_df[self.regulatory_label] = reg_label\n",
    "                # Keep track of this for quick access\n",
    "                self.encoded_df[reg_label] = reg_encoded_df\n",
    "                encoded_df = pd.concat([encoded_df, reg_encoded_df])\n",
    "        # Keep track of the patient encodings.\n",
    "        return encoded_df\n",
    "\n",
    "    def build_training_df(self, df, filter_extremes=True, selected_cases=None):\n",
    "        \"\"\"\n",
    "        Selected cases are the cases with matched tumour and normal for all conditions (or a selection\n",
    "        of cases that are used for training). This should be set otherwise all cases will be used and that\n",
    "        could be suboptimal.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: dataframe\n",
    "        filter_extremes: whether or not to remove data (genexpatient) if that value is > 2 out of z score true by default\n",
    "        selected_cases: the cases that are going to be used for training (list)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # We want to add all the case data as training data and just keep the columns in the correct order\n",
    "        # Basically we do this for all cases.\n",
    "        cases = self.patient_clinical_df[self.patient_id_column].values\n",
    "        train_df = pd.DataFrame()\n",
    "        case_ids = []\n",
    "        included_cases = []\n",
    "\n",
    "        if selected_cases is not None:\n",
    "            cases_subset = [c for c in cases if c in selected_cases]\n",
    "            cases = cases_subset\n",
    "        case_genes = None\n",
    "        if self.iid:\n",
    "            # Here is for the person with lots of money and resources who could actually make a big enough dataset\n",
    "            # Since I think the above works, maybe next time spend your money on better things like make a new journal\n",
    "            # where it's free to publish or the scientists actually get the royalties or something ya know...\n",
    "            # To do this, we take a single gene from each patient, i.e. first collect the patients, then subsample\n",
    "            # a single row that is unique between.\n",
    "            patients = cases #list(set([c.split('_')[0] for c in df.columns]))\n",
    "            n_genes = len(patients)\n",
    "            if n_genes > len(df.index.values) or self.iid > len(df.index.values):\n",
    "                n_genes = len(df.index.values) - 1\n",
    "            # Randomly select the a sample of genes for that patient\n",
    "            case_genes = []\n",
    "            for case_idx, case in enumerate(cases):\n",
    "                genes_for_patient = random.sample(list(enumerate(df.index.values)), n_genes)\n",
    "                case_genes.append([[c[0] for c in genes_for_patient], [c[1] for c in genes_for_patient]])\n",
    "            #case_genes = random.sample(list(enumerate(df.index.values)), n_genes)\n",
    "        for case_idx, case in enumerate(cases):\n",
    "            case_cond_df = pd.DataFrame()\n",
    "            if self.iid:\n",
    "                idval = case_genes[case_idx][1]\n",
    "                case_cond_df['id'] = idval\n",
    "            else:\n",
    "                case_cond_df['id'] = list(df.index.values)\n",
    "            for col in self.feature_columns:\n",
    "\n",
    "                    if self.iid:\n",
    "                        valval = case_genes[case_idx][0]\n",
    "                        v = df[f'{case}_{col}'].values[valval]\n",
    "                        # Just select the single gene that we're interested in\n",
    "                        case_cond_df[col] = v\n",
    "                    else:\n",
    "                        case_cond_df[col] = df[f'{case}_{col}'].values  # Get the column name from the case\n",
    "\n",
    "            # Add this to the cond_1_sample_df\n",
    "            if len(case_cond_df.columns) == len(self.feature_columns) + 1:  # For the index column\n",
    "                train_df = pd.concat([train_df, case_cond_df], ignore_index=True)\n",
    "                # Add the length of this to the case_ids list so we can extract this patient's information later\n",
    "                case_ids += [case] * len(case_cond_df)\n",
    "                included_cases.append(case)\n",
    "        train_df.set_index('id', inplace=True)\n",
    "        if filter_extremes:\n",
    "            z_score = np.abs(stats.zscore(train_df[self.feature_columns].values, axis=1))\n",
    "            max_z_score = np.max(z_score, axis=1)\n",
    "            train_df = train_df[max_z_score < 2]\n",
    "        self.u.dp([f'{len(included_cases)} had matched data.', included_cases])\n",
    "        return train_df\n",
    "\n",
    "    def normalise_df(self, df):\n",
    "        \"\"\"\n",
    "        Normalise the dataframe either at a row level or a column level.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # Next normalise\n",
    "        # We want to add all the case data as training data and just keep the columns in the correct order\n",
    "        # Basically we do this for all cases.\n",
    "\n",
    "        if self.normalise == 'rows':\n",
    "            data = df.values.copy()\n",
    "            # Min max scale this data\n",
    "            data_values = []  # Basically just going to normalise each row\n",
    "            for i, row in enumerate(data):\n",
    "                if row.max() == 0:\n",
    "                    data_values.append(row)\n",
    "                else:\n",
    "                    non_zero_min = np.min(row[row > 0])\n",
    "                    non_zero_max = np.max(row[row > 0])\n",
    "                    new_values = []\n",
    "                    for j, val in enumerate(row):\n",
    "                        if val > 0:\n",
    "                            new_values.append((val - non_zero_min) / (non_zero_max - non_zero_min))\n",
    "                        else:\n",
    "                            new_values.append(0)\n",
    "                    data_values.append(new_values)\n",
    "\n",
    "            # Refill in the normalised protein data\n",
    "            new_df = pd.DataFrame(data_values, index=df.index, columns=df.columns)\n",
    "            return new_df\n",
    "        elif self.normalise == 'columns':\n",
    "            scaled_df = pd.DataFrame()\n",
    "            scaled_df['genes'] = df.index.values\n",
    "            numeric_cols = [c for c in df.columns if c != self.regulatory_label and c != 'id']\n",
    "            # For each column, normalise to min-max but fist ommit any 0's\n",
    "            for col in numeric_cols:\n",
    "                values = df[col].values.copy()\n",
    "                if values.max() == 0:\n",
    "                    scaled_df[col] = values\n",
    "                else:\n",
    "                    non_zero_values = values[values != 0]\n",
    "                    min_nz = np.min(non_zero_values)\n",
    "                    max_nz = np.max(non_zero_values)\n",
    "                    values[values != 0] = (values[values != 0] - min_nz) / (max_nz - min_nz)  # Min max scale and\n",
    "                    # leave the rest 0's\n",
    "                    scaled_df[col] = values\n",
    "            scaled_df.set_index('genes', inplace=True)\n",
    "            return scaled_df\n",
    "\n",
    "    def fill_missing(self, df, case_id, sample_df, label):\n",
    "        \"\"\"\n",
    "        If the user wants to include the misisng data, do it either by the mean, or by a series of the\n",
    "        values associated with the patient sample types.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        case_id\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        if self.missing_method == 'mean':\n",
    "            cond_0 = list(sample_df[sample_df[self.condition_column] == 0][self.column_id].values)\n",
    "            cond_0_cols = [c for c in cond_0 if c in list(df.columns)]  # Ensure it is in the cols\n",
    "            return np.mean(df[cond_0_cols].values, axis=1)\n",
    "        if self.missing_method == 'clinical' and self.clinical_label != None:\n",
    "            # For now just do it on patient stage and age of patient\n",
    "            case_info = self.patient_clinical_df[self.patient_clinical_df[self.patient_id_column] == case_id]\n",
    "            # Get the information we care about ToDo: generalise\n",
    "            clin_val = case_info[self.clinical_label].values[0]\n",
    "            # Now let's get the values for that age and stage\n",
    "            other_cases = self.patient_clinical_df[self.patient_clinical_df[self.clinical_label] == clin_val]\n",
    "            # Now return the values for this for the given label that was asked for.\n",
    "            cond_0_columns = [c for c in other_cases[f'{label} Normal'].values if c in df.columns]  # The normal values for the cases with same\n",
    "            # age and stage\n",
    "            return np.mean(df[cond_0_columns].values, axis=1)\n",
    "\n",
    "    def compute_columns_training(self, df, sample_df, label, include_missing):\n",
    "        \"\"\"\n",
    "        Goal is to add in the data for the columns for the VAE training. For this context we're interested\n",
    "        in the tumour, normal, and logFC between the two.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df\n",
    "        label\n",
    "        include_missing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        vae_data_df = pd.DataFrame()  # This will be the data used for input\n",
    "        vae_data_df['id'] = df.index.values\n",
    "        # Get a baseline for all \"normal\"\n",
    "        cond_0 = sample_df[sample_df[self.condition_column] == 0]  # i.e. normal\n",
    "        cond_0_columns_all = [c for c in cond_0[self.column_id] if c is not None]\n",
    "        if len(cond_0_columns_all) == 0:\n",
    "            self.u.warn_p(['Dataset passed had no normal columns... you have an error please fix it!'])\n",
    "            return\n",
    "        # baseline.\n",
    "        for case in self.patient_clinical_df[self.patient_id_column].unique():\n",
    "            # Want to do condition 1 - condition 0 --> keeping with standard approach\n",
    "            case_df = self.patient_clinical_df[self.patient_clinical_df[self.patient_id_column] == case]\n",
    "            cond_0_column = case_df[f'{label} Normal'].values[0]\n",
    "            cond_1_column = case_df[f'{label} Tumour'].values[0]\n",
    "            # Require that must have cond_1 at least\n",
    "            if cond_1_column is not None:\n",
    "                if cond_0_column is None:\n",
    "                    if include_missing:\n",
    "                        cond_0_mean = self.fill_missing(df, case, sample_df, label)\n",
    "                        # If it doesn't have any NA, include this otherwise ommit the data\n",
    "                        print(cond_0_mean)\n",
    "                        if not np.isnan(cond_0_mean).any():\n",
    "                            cond_1_values = df[cond_1_column].values\n",
    "                            vae_data_df[f'{case}_{label}-Normal'] = cond_0_mean\n",
    "                            vae_data_df[f'{case}_{label}-Tumor'] = cond_1_values\n",
    "                            vae_data_df[f'{case}_{label}-LogFC'] = cond_1_values - cond_0_mean\n",
    "                else:\n",
    "                    # May only have 1 value for a patient - this summarises the replicates\n",
    "                    cond_0_values = df[cond_0_column].values\n",
    "                    cond_1_values = df[cond_1_column].values\n",
    "                    vae_data_df[f'{case}_{label}-Normal'] = cond_0_values\n",
    "                    vae_data_df[f'{case}_{label}-Tumor'] = cond_1_values\n",
    "                    vae_data_df[f'{case}_{label}-LogFC'] = cond_1_values - cond_0_values\n",
    "        # Set index\n",
    "        vae_data_df.set_index('id', inplace=True)\n",
    "        return vae_data_df\n",
    "\n",
    "    def train(self, train_df, feature_columns, reg_label, config=None):\n",
    "        \"\"\"\n",
    "        Train the vae.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df: a dataframe of rows which are patient gene values (i.e. n rows = patients x genes) and summarised\n",
    "        columns (i.e. RNA logFC, Protein logFC, ... etc for that patient for that gene).\n",
    "        feature_columns: the columns used for the VAE.\n",
    "        reg_label: the SiRCle cluster.\n",
    "        config: a dictionary of the config for the VAE. If None, then a default is used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            config = {\"loss\": {'loss_type': 'mse', 'distance_metric': 'mmd', 'mmd_weight': 0.25},\n",
    "                      \"encoding\": {\"layers\": [{\"num_nodes\": 5, \"activation_fn\": \"relu\"}]},\n",
    "                      \"decoding\": {\"layers\": [{\"num_nodes\": 5, \"activation_fn\": \"relu\"}]},\n",
    "                      \"latent\": {\"num_nodes\": 1},\n",
    "                      \"optimiser\": {\"params\": {'learning_rate': 0.01}, \"name\": \"adam\"},\n",
    "                      \"epochs\": 200,\n",
    "                      \"batch_size\": 16,\n",
    "                      \"scale_data\": False\n",
    "                      }\n",
    "        epochs = config.get('epochs', 100)\n",
    "        batch_size = config.get('batch_size', 16)\n",
    "        data_values = train_df[feature_columns].values\n",
    "        vae_m = VAE(data_values, data_values, list(train_df.index.values), config, vae_label=reg_label)\n",
    "        vae_m.encode('default', train_percent=75.0, epochs=epochs, batch_size=batch_size,\n",
    "                     logging_dir=self.output_folder,\n",
    "                     logfile=f'VAE-logfile-{reg_label}-{self.run_name}.txt', early_stop=True)\n",
    "        vae_m.save(weight_file_path=f'{self.output_folder}{reg_label}-{self.run_name}-VAE-weights.h5',\n",
    "                   optimizer_file_path=f'{self.output_folder}{reg_label}-{self.run_name}-VAE-optimizer.json',\n",
    "                   config_json=f'{self.output_folder}{reg_label}-{self.run_name}-VAE-config.json')  # save the VAE\n",
    "        # Save an encoding of the data in the class and return it to the user.\n",
    "        self.trained_vae[reg_label] = vae_m\n",
    "        vae_m.u.dp([\"Saved VAE to current directory.\"])\n",
    "        return vae_m\n",
    "\n",
    "    def get_decoding(self, reg_label):\n",
    "        if not self.trained_vae.get(reg_label):\n",
    "            self.u.err_p(['That regulatory label:', reg_label, 'did not exist in your dataset, please check the csv'\n",
    "                                                               'file to make sure it exists.',\n",
    "                          'Regulatory labels in your dataset:', list(self.trained_vae.keys())])\n",
    "        else:\n",
    "            vae_m = self.trained_vae[reg_label]\n",
    "            # Get the encoded data for that label\n",
    "            encoding = self.encoded_df[reg_label]\n",
    "            decoding_df = encoding[['id', self.regulatory_label]].copy()\n",
    "            for column in encoding.columns:\n",
    "                if column != 'id' and column != self.regulatory_label:\n",
    "                    encoding_vals = encoding[column].values\n",
    "                    decoding = vae_m.decoder.predict(np.array([np.array(c) for c in encoding_vals]))\n",
    "                    # The decoding will be in the same format as what we in\n",
    "                    for i, c in enumerate(self.feature_columns):\n",
    "                        decoding_df[f'{column}_{c}'] = decoding[:, i]\n",
    "            return decoding_df\n",
    "\n",
    "    def get_encoding(self, input_df, reg_label):\n",
    "        # Do this for each case, and then save as a DF for this cluster\n",
    "        r_df = pd.DataFrame()\n",
    "        r_df['id'] = input_df.index\n",
    "        # Just make sure everything is in the right order\n",
    "        vae_m = self.trained_vae[reg_label]\n",
    "        for case_id in self.patient_clinical_df[self.patient_id_column].unique():\n",
    "            case_cond_df = pd.DataFrame()\n",
    "            for col in self.feature_columns:\n",
    "                try:\n",
    "                    case_cond_df[col] = input_df[f'{case_id}_{col}'].values  # Get the column name from the case\n",
    "                except:\n",
    "                    continue\n",
    "            if len(case_cond_df.columns) == len(self.feature_columns):\n",
    "                encoded_data = vae_m.encode_new_data(case_cond_df.values, scale=False)\n",
    "                # For each of the cases add it as a column\n",
    "                r_df[case_id] = encoded_data\n",
    "            # else:\n",
    "            #     self.u.dp([\"CaseID: \", case_id, \" must have been missing tumour data...\"])\n",
    "        self.encoded_df[reg_label] = r_df  # Save to state as well while we're going.\n",
    "        return r_df\n",
    "\n",
    "    def align_to_rcm(self, df, rcm_df, include_regulatory_label=False, normalise=True):\n",
    "        aligned_df = pd.DataFrame()\n",
    "        aligned_df['genes'] = rcm_df.index\n",
    "        aligned_df.set_index('genes', inplace=True)\n",
    "        aligned_df = aligned_df.join(df, how='left')  # Get all the data aligned to the same index\n",
    "        aligned_df.fillna(0, inplace=True)  # Fill in the missing values with 0\n",
    "        # normalise df\n",
    "        if normalise:\n",
    "            normalised_aligned_df = self.normalise_df(aligned_df) # normalise the data\n",
    "            if include_regulatory_label:\n",
    "                normalised_aligned_df[self.regulatory_label] = rcm_df[self.regulatory_label].values\n",
    "            return normalised_aligned_df\n",
    "        else:\n",
    "            if include_regulatory_label:\n",
    "                aligned_df[self.regulatory_label] = rcm_df[self.regulatory_label].values\n",
    "                return aligned_df\n",
    "            return aligned_df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ad694f40",
   "metadata": {},
   "source": [
    "## Train or re-load saved version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dbee5ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "train = True\n",
    "if train:\n",
    "    epochs = 100 \n",
    "    batch_size = 16\n",
    "    num_nodes = 5\n",
    "    mmd_weight = 0.25\n",
    "    loss = {'loss_type': 'mse', 'distance_metric': 'mmd', 'mmd_weight': mmd_weight}\n",
    "    config = {\"loss\": loss,\n",
    "              \"encoding\": {\"layers\": [{\"num_nodes\": num_nodes, \"activation_fn\": \"relu\"}]},\n",
    "              \"decoding\": {\"layers\": [{\"num_nodes\": num_nodes, \"activation_fn\": \"relu\"}]},\n",
    "              \"latent\": {\"num_nodes\": 1},\n",
    "              \"optimiser\": {\"params\": {'learning_rate': 0.01}, \"name\": \"adam\"},\n",
    "              \"epochs\": epochs,\n",
    "              \"batch_size\": batch_size,\n",
    "              \"scale_data\": False\n",
    "              }\n",
    "    training_cases = matching_cases # Use matching cases for training\n",
    "    sv.train_vae(cases=matching_cases, config=config)\n",
    "    sv.save()  # Save the information we have generated.\n",
    "else:\n",
    "    sv.load_saved_vaes()\n",
    "    sv.load_saved_encodings(f'{sv.output_folder}encoded_df_{label}.csv')\n",
    "    sv.load_saved_inputs(f'{sv.output_folder}vae_input_df_{label}.csv')\n",
    "    sv.load_saved_raws(f'{sv.output_folder}raw_input_df_{label}.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183554f-6b4b-44e2-a3c5-9ccd010e2af7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ac95dc73",
   "metadata": {},
   "source": [
    "## Run the statistics on some different comparisons\n",
    "\n",
    "This works based on stuff in our sample data frame.\n",
    "\n",
    "We have a very small dataset (just the stage IV patients) so lets see, maybe just look at gender..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ef6b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example sample data frame\n",
    "sv.patient_clinical_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70054f2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sciutil import SciUtil\n",
    "u = SciUtil()\n",
    "u.warn_p(['Gender']) # Got to be the column name in the DF and then two of the conditions in that column\n",
    "# Note if you get something like: ValueError: `x` and `y` must be of nonzero size. \n",
    "# Probably means you didn't have enough patients to do this comparison.\n",
    "gender_df = sv.run_vae_stats(cond_label='gender', cond0='Female', cond1='Male')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d85b8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "gender_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ad902",
   "metadata": {
    "tags": []
   },
   "source": [
    "gender_df[gender_df['Integrated pval (Male-Female)'] < 0.05]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "185cc2e8",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Note, we can see that when comparing \"male\" and \"female\" we get no significant differences (using p.adj).\n",
    "We have two small groups here (Cond1: 4 vs Cond0: 5) and we're using a mann Whitney U test, which means that the ranks would basically need to be all different to get a significant p-value, and then this gets adjusted out. Things to just be wary of :)\n",
    "\n",
    "Why you ask do we only have 4 vs 5, it's because some of the patients are missing tumour data, we omit these from the analysis, and the inlcude missing currently is only for the patients with a normal sample missing. If you really want to include those patients, impute the missing tumour data for them (though this would be probably a bad idea).\n",
    "\n",
    "This was an example using a small dataset (because github limits the file size to 50MB), so try with your own data and if you get stuck please get in contact :) we're happy to help out!\n",
    "\n",
    "Final caveat that while we're using the column \"gender\" it may refer to gender or bioloigcal sex, but we're using public data so not actually sure, and also not sure if the form had the full range of genders that exist.\n",
    "There are lots of genders and hopefully in the future they will be more clear about whether it is gender or biological sex and ensure that in reporting everyone has the ability to specify how they identify if they so choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7216a-27f0-47d9-b5a5-bd4f755b1a61",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
